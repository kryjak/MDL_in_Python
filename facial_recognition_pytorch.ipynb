{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special as sp\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = pd.read_csv('../DL_and_NN_in_Python/fer2013.csv')\n",
    "df = df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511\n",
      "emotion                                                    5\n",
      "pixels     50 28 23 21 18 75 120 102 65 60 64 71 93 104 1...\n",
      "Usage                                               Training\n",
      "Name: 17088, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1318095/1637804024.py:7: DeprecationWarning: This function is deprecated. Please call randint(0, 4002 + 1) instead\n",
      "  random_no = np.random.random_integers(0, len(df_emotion))\n"
     ]
    }
   ],
   "source": [
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "def show_sample_image(emotion: int):\n",
    "    emotion_no = emotions.index(emotion)\n",
    "    df_emotion = df[df.emotion == emotion_no]\n",
    "\n",
    "    random_no = np.random.random_integers(0, len(df_emotion))\n",
    "    print(random_no)\n",
    "    print(df_emotion.iloc[random_no])\n",
    "\n",
    "    img = np.array(list(map(int, df_emotion.iloc[random_no].pixels.split(' '))), dtype=np.uint8).reshape((48,48))\n",
    "    img = PIL.Image.fromarray(img).resize((1000, 1000))\n",
    "    img.show()\n",
    "\n",
    "show_sample_image('Surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proportion = 0.8\n",
    "train_index = int(train_proportion*len(df))\n",
    "\n",
    "train_df = df.iloc[:train_index]\n",
    "test_df = df.iloc[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 28709, D = 2304, n_classes: 7\n",
      "Number of samples in training set: 28709\n",
      "Number of samples in test set: 7178\n"
     ]
    }
   ],
   "source": [
    "N = len(train_df)\n",
    "D = len(train_df.iloc[0].pixels.split(' '))\n",
    "D1 = int(np.sqrt(D))\n",
    "\n",
    "# or just use train_test_split from sklearn.model_selection for the same effect\n",
    "n_classes = len(set(train_df.emotion))\n",
    "\n",
    "print(f'N = {N}, D = {D}, n_classes: {n_classes}')\n",
    "\n",
    "print(f'Number of samples in training set: {len(train_df)}')\n",
    "print(f'Number of samples in test set: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom Dataset object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx, 0]\n",
    "        image = self.data.iloc[idx, 1]\n",
    "        image = list((map(int, image.split(' '))))\n",
    "        image = np.array(image).reshape((D1, D1))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data = CustomImageDataset(train_df, transform=ToTensor())\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_data = CustomImageDataset(test_df, transform=ToTensor())\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNs in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic behind creating a model in PyTorch is pretty much the same as in Tensorflow. There are some syntactical differences, though.\n",
    "\n",
    "1. The activation function is not specified as part of the layer, but separately.\n",
    "2. The input and output dimensions need to be supplied, unlike in Keras, where only output is needed. Note that in pure TF, without Keras, we also need to specify the intput dims unless we postpone the build of the model (see https://www.tensorflow.org/guide/intro_to_modules#waiting_to_create_variables)\n",
    "3. The input has to be explicitly turned into a torch.Tensor (TF can handle that automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPyTorch(torch.nn.Module):\n",
    "    def __init__(self, M: int = 10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(D1*D1, M),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M, n_classes)\n",
    "        )\n",
    "        self.double() # ensures input has the same dtype as the parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPyTorchV2(nn.Module):\n",
    "    def __init__(self, M: int = 10, activation_function = nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(D1*D1, M)\n",
    "        self.layer2 = nn.Linear(M, n_classes)\n",
    "        self.activation_function = activation_function\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.activation_function(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructNNPyTorch(M: int = 10, activation_function = nn.ReLU()):\n",
    "    model = nn.Sequential()\n",
    "    model.add_module('flatten', nn.Flatten())\n",
    "    model.add_module('name1', nn.Linear(D, M))\n",
    "    model.add_module('name2', activation_function)\n",
    "    model.add_module('name3', nn.Linear(M, n_classes))\n",
    "    model.double()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelPyTorch(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=7, bias=True)\n",
      "  )\n",
      ")\n",
      "ModelPyTorchV2(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Linear(in_features=2304, out_features=10, bias=True)\n",
      "  (layer2): Linear(in_features=10, out_features=7, bias=True)\n",
      "  (activation_function): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (name1): Linear(in_features=2304, out_features=10, bias=True)\n",
      "  (name2): ReLU()\n",
      "  (name3): Linear(in_features=10, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_v1 = ModelPyTorch().to(device)\n",
    "print(model_v1)\n",
    "model_v2 = ModelPyTorchV2().to(device)\n",
    "print(model_v2)\n",
    "model_v3 = constructNNPyTorch(M=10).to(device)\n",
    "print(model_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
